{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed Job Processing\n",
    "\n",
    "A common software development pattern for parallelization using Python is **delayed job processing**. This pattern is particularly useful for software that is designed to work on a multiple server architecture. Under this pattern a primary or **scheduler** process will schedule a job to be executed by a **worker** process at some later time. This pattern is used internally in high-performance/parallel libraries like Spark or Tensorflow, does the specifics of the implementation are abstracted away from us, and we need only worry about designing a processing graph.\n",
    "\n",
    "Here, we implement a scheduler/worker pattern manually using the `rq` (Redis queue) Python library. This library is typically used in web applications to trigger large jobs to be executed at a later time. For our purposes here it will help us to design a truly parallel implementation of MapReduce using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "\n",
    "The use the following list of strings as our \"documents\". This is to say that each string is a document that will be mapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"This paper presents a kernel-based principal component analysis, kernel PCA, to extract critical features for improving the performance of a stock trading model. \",\n",
    "\"The feature extraction method is one of the techniques to solve dimensionality reduction problems.\",\n",
    "\"The kernel PCA is a feature extraction approach which has been applied to data transformation from known variables to capture critical information.\",\n",
    "\"The kernel PCA is a kernel-based data mapping tool that has characteristics of both principal component analysis and non-linear mapping.\",\n",
    "\"The feature selection method is another DRP technique that selects only a small set of features from known variables, but these features still indicate possible collinearity problems that fail to reflect clear information.\",\n",
    "\"However, most feature extraction methods use a variable mapping application to eliminate noisy and collinear variables. In this research, we use the kernel-PCA method in a stock trading model to transform stock technical indices which allows features of smaller dimension to be formed.\",\n",
    "\"The kernel-PCA method has been applied to various stocks and sliding window testing methods using both half-year and 1-year testing strategies. The experimental results show that the proposed method generates more profits than other DRP methods on the America stock market.\",\n",
    "\"This stock trading model is very practical for real-world application, and it can be implemented in a real-time environment.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis import Redis \n",
    "from rq import Queue\n",
    "from lib.worker import remove_punctuation, mapper, reducer, toggle_hold, check_hold\n",
    "import time\n",
    "redis_connection = Redis('this_redis')\n",
    "job_queue = Queue(connection=redis_connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our previous implementation of the `word_count` function.\n",
    "\n",
    "    def word_count(documents, redis_connection, word_list='word_list'):\n",
    "\n",
    "        counts = []\n",
    "\n",
    "        for document in documents:\n",
    "            mapper(document, redis_connection, word_list)\n",
    "\n",
    "        word = redis_connection.spop(word_list)\n",
    "        while word:\n",
    "            word = word.decode()\n",
    "            count = reducer(word, redis_connection)\n",
    "            counts.append((word, count))\n",
    "            word = redis_connection.spop(word_list)\n",
    "\n",
    "        return counts\n",
    "        \n",
    "There are two candidates for parallelization in this function:\n",
    "\n",
    "1. the `for` loop can be parallelized as tokenization of one document is completely independent of the tokenization of another.\n",
    "1. the `while` loop can be parallelized as the counting of tokens for one word is completely independent of the counting of another.\n",
    "\n",
    "There was one tricky aspect to this parallelization, however. We cannot work on the word counts until all of the tokenization is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def word_count(documents, word_list='word_list', count_list='count_list'):\n",
    "    \n",
    "#     for document in documents:\n",
    "#         job = job_queue.enqueue(mapper, document, 'word_list')   \n",
    "        \n",
    "#     word = redis_connection.spop('word_list')x\n",
    "#     job_queue.enqueue(reducer, word, 'count_list', depends_on=job)\n",
    "    \n",
    "#     while word:\n",
    "#         word = word.decode()\n",
    "#         job_queue.enqueue(reducer, word, 'count_list')\n",
    "#         word = redis_connection.spop('word_list')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finished'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_documents(documents):\n",
    "    for document in documents:\n",
    "        job = job_queue.enqueue(mapper, document, 'word_list')\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queued'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = map_documents(documents)\n",
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finished'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_words():\n",
    "\n",
    "    word = redis_connection.spop('word_list')\n",
    "    while word:\n",
    "        word = word.decode()\n",
    "        job = job_queue.enqueue(reducer, word, 'count_list')\n",
    "        word = redis_connection.spop('word_list')\n",
    "    \n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = reduce_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queued'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_counts():\n",
    "    \n",
    "    counts = []\n",
    "    count = redis_connection.lpop('count_list')\n",
    "    while count:\n",
    "        counts.append(count)\n",
    "        count = redis_connection.lpop('count_list')\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"('information', 2)\",\n",
       " b\"('selects', 1)\",\n",
       " b\"('The', 6)\",\n",
       " b\"('a', 8)\",\n",
       " b\"('variables', 3)\",\n",
       " b\"('it', 1)\",\n",
       " b\"('tool', 1)\",\n",
       " b\"('be', 2)\",\n",
       " b\"('presents', 1)\",\n",
       " b\"('clear', 1)\",\n",
       " b\"('This', 2)\",\n",
       " b\"('model', 3)\",\n",
       " b\"('testing', 2)\",\n",
       " b\"('variable', 1)\",\n",
       " b\"('eliminate', 1)\",\n",
       " b\"('most', 1)\",\n",
       " b\"('solve', 1)\",\n",
       " b\"('DRP', 2)\",\n",
       " b\"('of', 5)\",\n",
       " b\"('experimental', 1)\",\n",
       " b\"('allows', 1)\",\n",
       " b\"('techniques', 1)\",\n",
       " b\"('to', 9)\",\n",
       " b\"('kernel', 3)\",\n",
       " b\"('kernelPCA', 2)\",\n",
       " b\"('more', 1)\",\n",
       " b\"('improving', 1)\",\n",
       " b\"('market', 1)\",\n",
       " b\"('In', 1)\",\n",
       " b\"('this', 1)\",\n",
       " b\"('However', 1)\",\n",
       " b\"('is', 5)\",\n",
       " b\"('capture', 1)\",\n",
       " b\"('PCA', 3)\",\n",
       " b\"('sliding', 1)\",\n",
       " b\"('these', 1)\",\n",
       " b\"('than', 1)\",\n",
       " b\"('proposed', 1)\",\n",
       " b\"('research', 1)\",\n",
       " b\"('dimension', 1)\",\n",
       " b\"('profits', 1)\",\n",
       " b\"('applied', 2)\",\n",
       " b\"('use', 2)\",\n",
       " b\"('but', 1)\",\n",
       " b\"('approach', 1)\",\n",
       " b\"('strategies', 1)\",\n",
       " b\"('application', 2)\",\n",
       " b\"('very', 1)\",\n",
       " b\"('can', 1)\",\n",
       " b\"('formed', 1)\",\n",
       " b\"('transformation', 1)\",\n",
       " b\"('small', 1)\",\n",
       " b\"('the', 5)\",\n",
       " b\"('method', 5)\",\n",
       " b\"('realworld', 1)\",\n",
       " b\"('set', 1)\",\n",
       " b\"('fail', 1)\",\n",
       " b\"('analysis', 2)\",\n",
       " b\"('we', 1)\",\n",
       " b\"('other', 1)\",\n",
       " b\"('in', 2)\",\n",
       " b\"('characteristics', 1)\",\n",
       " b\"('extract', 1)\",\n",
       " b\"('been', 2)\",\n",
       " b\"('still', 1)\",\n",
       " b\"('America', 1)\",\n",
       " b\"('problems', 2)\",\n",
       " b\"('for', 2)\",\n",
       " b\"('implemented', 1)\",\n",
       " b\"('features', 4)\",\n",
       " b\"('indicate', 1)\",\n",
       " b\"('technical', 1)\",\n",
       " b\"('indices', 1)\",\n",
       " b\"('kernelbased', 2)\",\n",
       " b\"('reduction', 1)\",\n",
       " b\"('on', 1)\",\n",
       " b\"('that', 4)\",\n",
       " b\"('smaller', 1)\",\n",
       " b\"('practical', 1)\",\n",
       " b\"('another', 1)\",\n",
       " b\"('nonlinear', 1)\",\n",
       " b\"('window', 1)\",\n",
       " b\"('using', 1)\",\n",
       " b\"('reflect', 1)\",\n",
       " b\"('various', 1)\",\n",
       " b\"('extraction', 3)\",\n",
       " b\"('data', 2)\",\n",
       " b\"('trading', 3)\",\n",
       " b\"('stock', 5)\",\n",
       " b\"('only', 1)\",\n",
       " b\"('collinearity', 1)\",\n",
       " b\"('halfyear', 1)\",\n",
       " b\"('dimensionality', 1)\",\n",
       " b\"('transform', 1)\",\n",
       " b\"('methods', 3)\",\n",
       " b\"('from', 2)\",\n",
       " b\"('selection', 1)\",\n",
       " b\"('component', 2)\",\n",
       " b\"('results', 1)\",\n",
       " b\"('environment', 1)\",\n",
       " b\"('performance', 1)\",\n",
       " b\"('stocks', 1)\",\n",
       " b\"('generates', 1)\",\n",
       " b\"('feature', 4)\",\n",
       " b\"('possible', 1)\",\n",
       " b\"('both', 2)\",\n",
       " b\"('has', 3)\",\n",
       " b\"('and', 5)\",\n",
       " b\"('realtime', 1)\",\n",
       " b\"('critical', 2)\",\n",
       " b\"('noisy', 1)\",\n",
       " b\"('1year', 1)\",\n",
       " b\"('which', 2)\",\n",
       " b\"('paper', 1)\",\n",
       " b\"('principal', 2)\",\n",
       " b\"('one', 1)\",\n",
       " b\"('show', 1)\",\n",
       " b\"('collinear', 1)\",\n",
       " b\"('mapping', 3)\",\n",
       " b\"('known', 2)\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
