{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run src/preprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next phase of this project we move into developing our machine learning models. We have previously about model selection and have considered managing the Bias-Variance Tradeoff as we fit our predictive model. We primarily focused on identifying the simplest possible model as a way to making sure that our model generalizes to new data. Now we expand on this by examining three new concepts in model assessment and selection.\n",
    "\n",
    "1. using cross-validation to study model variance\n",
    "1. applying regularization to help our models generalize\n",
    "1. using emsembling to help our models generalize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One commonly held misconceptions is that cross-validation can to help models to generalize. This is not the case. Rather, cross-validation can be used to help to identify potential issues and to optimize model hyperparameters toward the end of choosing the best possible model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Validation Set Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling technique and is simply the creative use of collected data. We have already seen a very simple cross-validation approach, the train-test split also called The Validation Set Approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](doc/img/Chapter5/5-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "5       143000\n",
       "6       307000\n",
       "7       200000\n",
       "8       129900\n",
       "9       118000\n",
       "10      129500\n",
       "11      345000\n",
       "12      144000\n",
       "13      279500\n",
       "14      157000\n",
       "15      132000\n",
       "16      149000\n",
       "17       90000\n",
       "18      159000\n",
       "19      139000\n",
       "20      325300\n",
       "21      139400\n",
       "22      230000\n",
       "23      129900\n",
       "24      154000\n",
       "25      256300\n",
       "26      134800\n",
       "27      306000\n",
       "28      207500\n",
       "29       68500\n",
       "         ...  \n",
       "1430    192140\n",
       "1431    143750\n",
       "1432     64500\n",
       "1433    186500\n",
       "1434    160000\n",
       "1435    174000\n",
       "1436    120500\n",
       "1437    394617\n",
       "1438    149700\n",
       "1439    197000\n",
       "1440    191000\n",
       "1441    149300\n",
       "1442    310000\n",
       "1443    121000\n",
       "1444    179600\n",
       "1445    129000\n",
       "1446    157900\n",
       "1447    240000\n",
       "1448    112000\n",
       "1449     92000\n",
       "1450    136000\n",
       "1451    287090\n",
       "1452    145000\n",
       "1453     84500\n",
       "1454    185000\n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zoning_df = pd.read_csv('data/zoning.csv')\n",
    "listing_df = pd.read_csv('data/listing.csv')\n",
    "sale_df = pd.read_csv('data/sale.csv')\n",
    "\n",
    "housing_df = pd.merge(zoning_df, listing_df, left_on=\"Id\", right_on=\"Id\")\n",
    "housing_df = pd.merge(housing_df, sale_df, left_on=\"Id\", right_on=\"Id\")\n",
    "housing_df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id\n",
       "1       208500\n",
       "2       181500\n",
       "3       223500\n",
       "4       140000\n",
       "5       250000\n",
       "6       143000\n",
       "7       307000\n",
       "8       200000\n",
       "9       129900\n",
       "10      118000\n",
       "11      129500\n",
       "12      345000\n",
       "13      144000\n",
       "14      279500\n",
       "15      157000\n",
       "16      132000\n",
       "17      149000\n",
       "18       90000\n",
       "19      159000\n",
       "20      139000\n",
       "21      325300\n",
       "22      139400\n",
       "23      230000\n",
       "24      129900\n",
       "25      154000\n",
       "26      256300\n",
       "27      134800\n",
       "28      306000\n",
       "29      207500\n",
       "30       68500\n",
       "         ...  \n",
       "1431    192140\n",
       "1432    143750\n",
       "1433     64500\n",
       "1434    186500\n",
       "1435    160000\n",
       "1436    174000\n",
       "1437    120500\n",
       "1438    394617\n",
       "1439    149700\n",
       "1440    197000\n",
       "1441    191000\n",
       "1442    149300\n",
       "1443    310000\n",
       "1444    121000\n",
       "1445    179600\n",
       "1446    129000\n",
       "1447    157900\n",
       "1448    240000\n",
       "1449    112000\n",
       "1450     92000\n",
       "1451    136000\n",
       "1452    287090\n",
       "1453    145000\n",
       "1454     84500\n",
       "1455    185000\n",
       "1456    175000\n",
       "1457    210000\n",
       "1458    266500\n",
       "1459    142125\n",
       "1460    147500\n",
       "Name: SalePrice, Length: 1444, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_log_std_sc_out_rem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1444, 382), (1444, 390), (1444, 382), (1444, 390))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset_1.shape,\n",
    " dataset_2.shape,\n",
    " dataset_3.shape,\n",
    " dataset_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(dataset_1.index, target_1.index)\n",
    "np.testing.assert_allclose(dataset_2.index, target_2.index)\n",
    "np.testing.assert_allclose(dataset_3.index, target_3.index)\n",
    "np.testing.assert_allclose(dataset_4.index, target_4.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttsplit_1 = train_test_split(dataset_1, target_1, test_size=0.4, random_state=0)\n",
    "ttsplit_2 = train_test_split(dataset_2, target_1, test_size=0.4, random_state=0)\n",
    "ttsplit_3 = train_test_split(dataset_3, target_1, test_size=0.4, random_state=0)\n",
    "ttsplit_4 = train_test_split(dataset_4, target_1, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttsplit_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(model, data):\n",
    "    X_train = data[0]\n",
    "    X_test  = data[1]\n",
    "    y_train = data[2]\n",
    "    y_test  = data[3]\n",
    "    \n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end = time() - start \n",
    "    return model.score(X_test, y_test),end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.89860862751808546, 0.03981661796569824)\n",
      "(0.89858141337740194, 0.012806177139282227)\n",
      "(0.89924977700919972, 0.011998176574707031)\n",
      "(0.89931145722760453, 0.012408018112182617)\n"
     ]
    }
   ],
   "source": [
    "print(fit_score(Ridge(max_iter=1E5), ttsplit_1))\n",
    "print(fit_score(Ridge(max_iter=1E5), ttsplit_2))\n",
    "print(fit_score(Ridge(max_iter=1E5), ttsplit_3))\n",
    "print(fit_score(Ridge(max_iter=1E5), ttsplit_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.87587594870369745, 1.19460129737854)\n",
      "(0.87587068045006999, 7.579938888549805)\n",
      "(0.87344492815283614, 0.810370922088623)\n",
      "(0.87345736287380238, 4.375954627990723)\n"
     ]
    }
   ],
   "source": [
    "print(fit_score(Lasso(max_iter=1E4), ttsplit_1))\n",
    "print(fit_score(Lasso(max_iter=1E5), ttsplit_2))\n",
    "print(fit_score(Lasso(max_iter=1E4), ttsplit_3))\n",
    "print(fit_score(Lasso(max_iter=1E5), ttsplit_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-One-Out Cross-Validation\n",
    "\n",
    "An alternative to using a single validation set is using **leave-one-out cross-validation** (LOOCV). \n",
    "\n",
    "![](doc/img/Chapter5/5-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, instead of creating two sets, we create $n$ sets and fit $n$ models. Using this method, each data point is used as a testing point exactly once. To assess the performance we simply take the average over all models\n",
    "\n",
    "$$\\text{CV}_n=\\mathbb{E}\\left[MSE(f_i)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One draw back to this approach is the substantial time required to set a model for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_loo(model, dataset, target):\n",
    "    loo = LeaveOneOut()\n",
    "    scores = []\n",
    "    for train, test in loo.split(dataset, target):\n",
    "        train = dataset.index[train]\n",
    "        test = dataset.index[test]\n",
    "\n",
    "        X_train = dataset.loc[train]\n",
    "        X_test  = dataset.loc[test]\n",
    "        y_train = target.loc[train]\n",
    "        y_test  = target.loc[test]\n",
    "    \n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    print(\"Mean: {} Variance: {}\".format(scores.mean(), scores.var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length 1444 scores after calculation for dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0 Variance: 0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(fit_score_loo(Ridge(), dataset_1, target_1))\n",
    "# print(fit_score_loo(Ridge(), dataset_2, target_2))\n",
    "# print(fit_score_loo(Ridge(), dataset_3, target_3))\n",
    "# print(fit_score_loo(Ridge(), dataset_4, target_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fit_score_loo(Lasso(), dataset_1, target_1))\n",
    "# print(fit_score_loo(Lasso(), dataset_2, target_2))\n",
    "# print(fit_score_loo(Lasso(), dataset_3, target_3))\n",
    "# print(fit_score_loo(Lasso(), dataset_4, target_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is usually not practical to use LOOCV. Unacceptable alternative is to use **k-fold cross-validation** (KCV). In this method the data set is split into $k$ groups. Then, $k$ models are fit. Uses exactly one of the groups as a validation set And the remaining data as the training set. As before, the cross validation score is simply the average of the scores across all of the models\n",
    "\n",
    "$$\\text{CV}_k=\\mathbb{E}\\left[MSE(f_i)\\right]$$\n",
    "\n",
    "![](doc/img/Chapter5/5-5.png)\n",
    "\n",
    "Typical values of $k$ are $k=5$ or $k=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score_kfold(model, dataset, target, folds=5):\n",
    "    kf = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    start = time()\n",
    "    for train, test in kf.split(dataset, target):\n",
    "        train = dataset.index[train]\n",
    "        test = dataset.index[test]\n",
    "\n",
    "        X_train = dataset.loc[train]\n",
    "        X_test  = dataset.loc[test]\n",
    "        y_train = target.loc[train]\n",
    "        y_test  = target.loc[test]\n",
    "    \n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    \n",
    "    scores = np.array(scores)\n",
    "    end = time() - start \n",
    "\n",
    "    print(\"Mean: {:6} Variance: {:6} Time: {:6}\".format(scores.mean(), scores.var(), end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the data:\n",
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(dataset_1, target_1):\n",
    "    train = dataset_1.index[train]\n",
    "    test = dataset_1.index[test]\n",
    "    \n",
    "    X_train = dataset_1.loc[train]\n",
    "    X_test  = dataset_1.loc[test]\n",
    "    y_train = dataset_1.loc[train]\n",
    "    y_test  = dataset_1.loc[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[289, 290, 291, 292, 293, 294, 295, 296, 297, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[289, 290, 291, 292, 293, 294, 295, 296, 297, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[578, 579, 580, 581, 582, 583, 584, 585, 586, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[867, 868, 869, 870, 871, 872, 873, 874, 875, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[1156, 1157, 1158, 1159, 1160, 1161, 1162, 116...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [289, 290, 291, 292, 293, 294, 295, 296, 297, ...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                                   1  \n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "1  [289, 290, 291, 292, 293, 294, 295, 296, 297, ...  \n",
       "2  [578, 579, 580, 581, 582, 583, 584, 585, 586, ...  \n",
       "3  [867, 868, 869, 870, 871, 872, 873, 874, 875, ...  \n",
       "4  [1156, 1157, 1158, 1159, 1160, 1161, 1162, 116...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kftest = kf.split(dataset_1, target_1)\n",
    "dftest = pd.DataFrame(list(kftest))\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of 5 scores: array([ 0.99847548,  0.99813734,  0.99802722,  0.99837401,  0.99761703])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.8853121172449192 Variance: 0.00022291442467840236 Time: 0.1361231803894043\n",
      "Mean: 0.8853098855630306 Variance: 0.0002225420260587801 Time: 0.10610556602478027\n",
      "Mean: 0.8855857104448723 Variance: 0.0002238401520438682 Time: 0.10524654388427734\n",
      "Mean: 0.8855861191098917 Variance: 0.00022437950348525468 Time: 0.10732865333557129\n"
     ]
    }
   ],
   "source": [
    "fit_score_kfold(Ridge(), dataset_1, target_1)\n",
    "fit_score_kfold(Ridge(), dataset_2, target_2)\n",
    "fit_score_kfold(Ridge(), dataset_3, target_3)\n",
    "fit_score_kfold(Ridge(), dataset_4, target_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.8705352790807519 Variance: 0.0003678074887980236 Time: 2.3268306255340576\n",
      "Mean: 0.8705030078286796 Variance: 0.00037058614194948483 Time: 2.3912527561187744\n",
      "Mean: 0.8676419438563763 Variance: 0.00021040580637601944 Time: 2.2835559844970703\n",
      "Mean: 0.867624853279915 Variance: 0.0002079946079796495 Time: 2.022021770477295\n"
     ]
    }
   ],
   "source": [
    "fit_score_kfold(Lasso(), dataset_1, target_1)\n",
    "fit_score_kfold(Lasso(), dataset_2, target_2)\n",
    "fit_score_kfold(Lasso(), dataset_3, target_3)\n",
    "fit_score_kfold(Lasso(), dataset_4, target_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-Variance Trade-Off for k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of bias, it is clear that LOOCV will have lower bias than KCV when $k < n$. This is because each model is trained using $n-1$ points which is nearly all of the training data. Since KCV uses less of the data, it has less ability to learn the phenomenon represented by the data and is therefore more biased then LOOCV.\n",
    "\n",
    "On the other hand, LOOCV has more variance than KCV. This is because LOOCV involve the fitting and then averaging of performance of $n$ models, whereas KCV does this over $k$ models. Furthermore, the $n$ LOOCV models are more correlated with each other than are the $k$ KCV models. This is clear because each LOOCV model is identical to any other LOOCV model save for one point. Meanwhile each KCV model differs from any other KCV model in $n/k$ points. It can be shown that the meani of highly correlated quantities has higher variance then does the mean of quantities that are not as highly correlated. In other words, the LOOCV has higher variance than does the KCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
